
---
title: "Machine Learning Project"
author: "Winston Saunders"
date: "Dec 2014"
output: html_document
---

###Summary

this is part of the Coursera "Machine Learning" Coursera taught by Roger Peng, Jeff Leek, and 

the data used here come from this [source](http://groupware.les.inf.puc-rio.br/har). 

###Getting and cleaning data

```{r, echo=FALSE}

if(getwd()!="/Users/winstonsaunders/Documents/MachineLearningProject") setwd("MachineLearningProject")

##Read the files assigning na.strings

training<-read.csv("pml-training.csv", na.strings=c("", "NA"))
testing<-read.csv("pml-testing.csv", na.strings=c("", "NA"))

```

The raw training set consists of `r dim(training)[1]` rows and `r dim(training)[2]` columns.

```{r "look", eval=FALSE, echo=FALSE}

##look at raw data

head(training,2)

head(testing, 2)

```

Inspection reveals there are many NA values in the data. To keep these from biasing results and to simplify the analysis, I choose to eliminate those columnes with nigh numbers (>50%) of NA values. The cleaning also eliminates non-data columns like timestamps, etc.

```{r , echo=FALSE}
#number of observations
nObs<-length(training$classe)
```



```{r, echo=FALSE}

Ctraining<-training[, colSums(is.na(training))/nObs<.5]
#eliminate the same columns from the testing data 
Ctesting<-testing[, colSums(is.na(training))/nObs<.5] 

#Ctraining[1:5, 1:10]

##Get rid of non-data columns

Ctraining<-Ctraining[,8:ncol(Ctraining)]
Ctesting<-Ctesting[,8:ncol(Ctesting)]

#Ctraining$classe<-as.factor(Ctraining$classe)
#Ctesting$classe<-as.factor(Ctesting$classe)

str(Ctraining)

#Ctraining[1:5, 1:10]
#dim(training)



##verify no NAs left
##colSums(is.na(Ctraining))

```

THis cleaning reduces the number of data columns from `r dim(training)[2]` to `r dim(Ctraining)[2]`. The testing data also is reduced to `r dim(Ctesting)[2]` columns.

###Creating a Model

First step is to divide the taining data into a pair of training and test data in order to test the reliability of model development. 

```{r, echo=FALSE}
library(caret)
#library(AppliedPredictiveModeling)

set.seed(8675309)

        inTrain <- createDataPartition(y=Ctraining$classe, p=0.60, list=FALSE) 
        Train <- Ctraining[inTrain,] 
        Test <- Ctraining[-inTrain,]

```


###Plot a few dependencies to get an idea of what the data look like

```{r}

colnames(Train)

par(mfrow=c(2,2))
plot(Train$classe,Train[,2], color="red")
plot(Train$classe,Train[,27], color="blue")
plot(Train$classe,Train[,39], color="darkred")
plot(Train$classe,Train[,51], color="darkgreen")



```

###Build model

A principal components analysis shows that we require 20 variables to explain 90% of the observed variation and 26 variables to explain 95% of the variation. 


```{r}

last<-ncol(Train)
prep_Train<-preProcess(Train[,-last])
centerscaled<-predict(prep_Train, Train[,-last])
summary(prcomp(centerscaled))



#model <- train(classe~., data = Train, method="rf", trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE,verboseIter = TRUE))


```


```{r}
        ##new variables
        pcaprep<-preProcess(Train[,-last], method="pca", pcaComp=10)
        TrainPCA<-predict(pcaprep, Train[,-last])

        summary(TrainPCA)

        head(TrainPCA)

        ##use to build model
        #model<-train(Train$classe~., method="binomial", data=TrainPCA)

        ##understand how long calculation in taking
        time0 <- proc.time()

        model1 <- train(classe~., data = Train, method="rf", trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE,verboseIter = TRUE))

        calctime<-proc.time()-time0

        ##Show the calculation time
        calctime

        ##use the model to make a prediction
        prediction1 <- predict(model1, Test)
        ##test confusion matrix
        confusionMatrix(Test$classe, prediction1)

        

        #model2<-train(Train$classe~., method="glm", data=Train)

        #confusionMatrix(Test$classe,predict(modelfit,Test))
```

