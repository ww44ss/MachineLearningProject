
---
title: "Machine Learning Project"
author: "Winston Saunders"
date: "Dec 2014"
output: html_document
---

###Summary

Project for the Coursera "Machine Learning" course taught by Roger Peng, Jeff Leek, and Brian Caffo of the Dept of Statistics of the Bloomberg School at Johns Hopkins University.

The data used for this project have been generously provided by [Groupware Brasil](http://groupware.les.inf.puc-rio.br/har). 

###A: Getting and cleaning data

```{r, echo=FALSE}

if(getwd()!="/Users/winstonsaunders/Documents/MachineLearningProject") setwd("MachineLearningProject")

##Read the files assigning na.strings to blanks and "NA"
training<-read.csv("pml-training.csv", na.strings=c("", "NA"))
testing<-read.csv("pml-testing.csv", na.strings=c("", "NA"))

```

The raw training set consists of `r dim(training)[1]` rows and `r dim(training)[2]` columns.

```{r "look", eval=FALSE, echo=FALSE}

##look at raw data

head(training,2)

head(testing, 2)

```

Inspection reveals there are many NA values in the data. A historgram shows that there are really two classes of columns. Those with data and those without. To filter them I choose to eliminate those columnes with nigh numbers (>50%) of NA values.   
The cleaning also includes steps to eliminate non-data columns like timestamps, etc.

```{r , echo=FALSE}
#number of observations
nObs<-length(training$classe)
```

Here is a look at the raw data, showing both relevant and non-relevant data.

```{r, echo=7}
##This code chunk clean up the data and creates macro cleaned data sets Ctraining and Ctesting.
        ##eliminate "high NA value" columns
        Ctraining<-training[, colSums(is.na(training))/nObs<.5]
        #eliminate the same columns from the testing data 
        Ctesting<-testing[, colSums(is.na(training))/nObs<.5] 
        ##inspect the Ctraining Dataset
        Ctraining[1:3, 3:9]

##Get rid of non-data columns

        Ctraining<-Ctraining[,8:ncol(Ctraining)]
        Ctesting<-Ctesting[,8:ncol(Ctesting)]

        ##verify no NAs left
        ##colSums(is.na(Ctraining))

```

Cleaning reduces the number of data columns from `r dim(training)[2]` to `r dim(Ctraining)[2]`. The testing data also is reduced to `r dim(Ctesting)[2]` columns as would be expected.  

###B: Data Exploration

Here we look into the data to understand its behavior.  

####B.1: Dividing the Test Data into a training and test subset.  
Since the first step is to divide the taining data into a training and test datasets in order to test the reliability of model development before making predictions. This is required by the problem, which requests cross validation of the model.  

```{r, echo=6:8, message=FALSE}
library(caret)
#library(AppliedPredictiveModeling)

        set.seed(8675309)
        ## Divide the Cleaned Training Data into a Train and Test Data set
        inTrain <- createDataPartition(y=Ctraining$classe, p=0.60, list=FALSE) 
        Train <- Ctraining[inTrain,] 
        Test <- Ctraining[-inTrain,]

```


####B.2:Plot a few dependencies to get an idea of what the data look like

In general is it hard to see strong dependencies of any particular variable. 
```{r, echo=FALSE}

par(mfrow=c(2,3))
plot(Train$classe,Train[,2])
plot(Train$classe,Train[,16])
plot(Train$classe,Train[,28])
plot(Train$classe,Train[,31])
plot(Train$classe,Train[,40])
plot(Train$classe,Train[,52])

```

###C: Building a Model



```{r, eval=FALSE, echo=FALSE}
##This is some code I did not use in teh final project.
##I could not get it to work but intend to come back to it.

##Analysis to find out how many variables are needed to do describe the data.

        last<-ncol(Train)
        prep_Train<-preProcess(Train[,-last])
        centerscaled<-predict(prep_Train, Train[,-last])
        summary(prcomp(centerscaled))


```


```{r, eval=FALSE, echo=FALSE}
        ##new variables
        pcaprep<-preProcess(Train[,-last], method="pca", pcaComp=10)
        TrainPCA<-predict(pcaprep, Train[,-last])

##Build Random Forest Model
        #Start a timer
        time0 <- proc.time()
        
        modelPCA<-train(Train$classe~., method="rf", data=TrainPCA)

        calctime<-proc.time()-time0

 ##use the model to make a prediction using the raw data
        predictionPCA <- predict(modelPCA, Test[,-last])
        ##test confusion matrix
        confusionMatrix(Test$classe, predictionPCA)


```
Model the training data using the random forest technique. I played around with the parameters a bit to optimize execution 

```{r "run model", echo=6:7}
        ##Run this
        last<-ncol(Train)
        ##understand how long calculation in taking
        time0 <- proc.time()
        ##here is the model
        model1 <- train(classe~., data = Train, method="rf", 
                        trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE))

        calctime<-proc.time()-time0
```

The confusion matrix shows the accuracy of the model is very high. 

```{r, echo=5}

        ##use the model to make a prediction using the raw data
        prediction1 <- predict(model1, Test)
        ##test confusion matrix
        confusionMatrix(Test$classe, prediction1)

        

        #model2<-train(Train$classe~., method="glm", data=Train)

        #confusionMatrix(Test$classe,predict(modelfit,Test))
```

According to it the model has an accuracy of 99.3% according to this analysis and hence an estimated out of sample error rate of 0.7%. To be honest that blows me away. 

For information this calculation took `r calctime[3]` seconds of elapsed time and `r calctime[2]` seconds of system time on a _MacBook Air_. Every time I ran it the battery dropped about 6%!!!
  
###D. Using the model to make Predictions

We can use the model to make predictions on the testing data set from the exercise. The model makes all predictions accurately. 

```{r "evaluate test data", echo=1}
        answers<-predict(model1, Ctesting)
        
        answertable<-cbind(Ctesting[, last], answers)

        answertable

```

```{r "create file for answers", echo=FALSE}
        ##create function to store answers as text file per instructions
        pml_write_files = function(x){
                n = length(x)
                        for(i in 1:n){
                        filename = paste0("problem_id_",i,".txt")
                        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
                        }
                }
 
        ##Write the answers
        pml_write_files(answers)

```
